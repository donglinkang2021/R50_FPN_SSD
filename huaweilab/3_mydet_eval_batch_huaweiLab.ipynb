{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估模型\n",
    "\n",
    "上面的测试过程是一张一张图片进行预测的，这样的话速度会很慢，所以我们可以对图片进行批量处理，这样的话速度会快很多。所以我们需要对预测函数进行修改，使其能够批量处理图片。\n",
    "\n",
    "### 定义测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((256, 256))\n",
    "])\n",
    "\n",
    "# 将灰度图的数据集转换成RGB图像\n",
    "transform_gray = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((256, 256))\n",
    "])\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            data_dir, \n",
    "            img_paths,\n",
    "            transform=transform,\n",
    "            transform_gray=transform_gray\n",
    "        ):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.transform_gray = transform_gray\n",
    "        # self.imgs = os.listdir(data_dir)\n",
    "        self.imgs = img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.data_dir, self.imgs[idx])\n",
    "        img = Image.open(img_path)\n",
    "        if img.mode == 'RGB':\n",
    "            img = self.transform(img)\n",
    "        elif img.mode == 'L':\n",
    "            img = self.transform_gray(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看提交格式\n",
    "\n",
    "提前查看一下测试集的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45331</td>\n",
       "      <td>0045331.jpg</td>\n",
       "      <td>640</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35639</td>\n",
       "      <td>0035639.jpg</td>\n",
       "      <td>640</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33770</td>\n",
       "      <td>0033770.jpg</td>\n",
       "      <td>640</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42479</td>\n",
       "      <td>0042479.jpg</td>\n",
       "      <td>640</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44556</td>\n",
       "      <td>0044556.jpg</td>\n",
       "      <td>640</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id   image_path  width  height\n",
       "0     45331  0045331.jpg    640     169\n",
       "1     35639  0035639.jpg    640     176\n",
       "2     33770  0033770.jpg    640     178\n",
       "3     42479  0042479.jpg    640     186\n",
       "4     44556  0044556.jpg    640     193"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_images = pd.read_csv('test_images.csv', header=0)\n",
    "test_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submit = pd.DataFrame(columns=['image_id', 'predictions'])\n",
    "my_submit['image_id'] = test_images['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0045331.jpg', '0035639.jpg', '0033770.jpg', '0042479.jpg', '0044556.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_paths = test_images['image_path'].tolist()\n",
    "img_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0045331.jpg', 16362)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dir = \"./dl_detection/test/\"\n",
    "Cocodata_test = TestDataset(\n",
    "    test_data_dir,\n",
    "    img_paths\n",
    ")\n",
    "Cocodata_test.imgs[0], Cocodata_test.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始批量预测\n",
    "\n",
    "加载训练好的模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.device import try_gpu\n",
    "from mydet.model import R50_FPN_SSD\n",
    "device = try_gpu()\n",
    "# 在这里加载训练好的模型\n",
    "net = torch.load('resnet50_fpn_ssd_huawei2.pth',map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    Cocodata_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mydet.bbox.postprocessor import BBoxPostProcessor\n",
    "from mydet.bbox.postprocessor import bbox_filter\n",
    "import torch.nn.functional as F\n",
    "from utils.submit import bboxListToStr\n",
    "\n",
    "bbpp = BBoxPostProcessor(\n",
    "    nms_threshold=0.5,\n",
    "    neg_threshold=0.00999,\n",
    "    device = device\n",
    ")\n",
    "\n",
    "def predict_batch(X, batch_idx):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        batch_size = X.shape[0]\n",
    "        anchors, cls_preds, bbox_preds = net(X.to(device))\n",
    "        cls_probs = F.softmax(cls_preds, dim=2).permute(0, 2, 1) # 利用softmax转换成概率\n",
    "        output = bbpp.multibox_detection(cls_probs, bbox_preds, anchors)\n",
    "        # 去除掉背景类\n",
    "        for sample_idx in range(batch_size):\n",
    "            # 获取图片的宽和高信息\n",
    "            image_idx = batch_idx * batch_size + sample_idx\n",
    "            w = test_images['width'][image_idx]\n",
    "            h = test_images['height'][image_idx]\n",
    "            bbox_scale = torch.tensor([w, h, w, h], dtype=torch.float32, device=device)\n",
    "            # 去除掉背景类\n",
    "            idx = [i for i, sample in enumerate(output[sample_idx]) if sample[0] != -1]\n",
    "            sample_without_background = output[sample_idx][idx]\n",
    "            # 过滤掉一些预测框\n",
    "            sample_good = bbox_filter(sample_without_background)\n",
    "            # 如果一个类别的预测框超过300个，只取前300个（置信度从高到低排序）\n",
    "            if len(sample_good) > 300:\n",
    "                sample_good = sample_good[:300]\n",
    "\n",
    "            bbox_xyxy = sample_good[:, 2:] * bbox_scale\n",
    "            bbox_labels = sample_good[:, 0]\n",
    "            bbox_confs = sample_good[:, 1]\n",
    "\n",
    "            sample_good = torch.cat(\n",
    "                [\n",
    "                    bbox_xyxy,\n",
    "                    bbox_confs.unsqueeze(1),\n",
    "                    bbox_labels.unsqueeze(1),\n",
    "                ],\n",
    "                dim=1\n",
    "            )\n",
    "\n",
    "            # 将预测框转换成字符串并保存到my_submit中\n",
    "            my_submit.loc[image_idx, 'predictions'] = bboxListToStr(sample_good.cpu().numpy().tolist())\n",
    "            # print('batch_idx: %d, sample_idx: %d, sample_good: %d' % (batch_idx, sample_idx, len(sample_good)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |███████████████████████---------------------------| 46.09% Complete\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_88952/483751344.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpredict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     print_progress_bar(\n",
      "\u001b[0;32m/tmp/ipykernel_88952/2505885775.py\u001b[0m in \u001b[0;36mpredict_batch\u001b[0;34m(X, batch_idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcls_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 利用softmax转换成概率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultibox_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# 去除掉背景类\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/mydet/bbox/postprocessor.py\u001b[0m in \u001b[0;36mmultibox_detection\u001b[0;34m(self, cls_probs, offset_preds, anchors)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mpredicted_bb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_coder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox_nms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_bb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# 找到所有的non_keep索引，并将类设置为背景\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/mydet/bbox/iou_nms.py\u001b[0m in \u001b[0;36mbbox_nms\u001b[0;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[1;32m     57\u001b[0m         iou = bbox_iou(\n\u001b[1;32m     58\u001b[0m             \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         ).reshape(-1)\n\u001b[1;32m     61\u001b[0m         \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/mydet/bbox/iou_nms.py\u001b[0m in \u001b[0;36mbbox_iou\u001b[0;34m(boxes1, boxes2)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# inter_areas union_areas的形状:(boxes1的数量,boxes2的数量)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0minter_areas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0munion_areas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mareas1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mareas2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minter_areas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minter_areas\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0munion_areas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils.print_tools import print_progress_bar\n",
    "# 开始预测\n",
    "for batch_idx, X in enumerate(test_dataloader):\n",
    "    # 如果my_submit.csv已经存在该部分数据的预测结果，则跳过\n",
    "    if batch_idx * batch_size < my_submit['predictions'].count() :\n",
    "        continue\n",
    "\n",
    "    predict_batch(X, batch_idx)\n",
    "    \n",
    "    print_progress_bar(\n",
    "        batch_idx + 1, \n",
    "        len(test_dataloader), \n",
    "        prefix='Progress:', \n",
    "        suffix='Complete', \n",
    "        decimals=2,\n",
    "        length=50,\n",
    "        fill = \"█\"\n",
    "    )\n",
    "    # 每5个batch保存一次\n",
    "    if (batch_idx + 3) % 3 == 0:\n",
    "        my_submit.to_csv('my_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(X):\n",
    "#     net.eval()\n",
    "#     with torch.no_grad():\n",
    "#         batch_size = X.shape[0]\n",
    "#         anchors, cls_preds, bbox_preds = net(X.to(device))\n",
    "#         cls_probs = F.softmax(cls_preds, dim=2).permute(0, 2, 1) # 利用softmax转换成概率\n",
    "#         output = bbpp.multibox_detection(cls_probs, bbox_preds, anchors)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.print_tools import print_progress_bar\n",
    "# all_predictions = torch.tensor([], dtype=torch.float32, device=device) # 保存所有的预测结果\n",
    "# for batch_idx, X in enumerate(test_dataloader):\n",
    "#     output = predict(X)\n",
    "#     all_predictions = torch.cat([all_predictions, output], dim=0)\n",
    "#     print_progress_bar(\n",
    "#         batch_idx + 1, \n",
    "#         len(test_dataloader), \n",
    "#         prefix='Progress:', \n",
    "#         suffix='Complete', \n",
    "#         decimals=2,\n",
    "#         length=50,\n",
    "#         fill = \"█\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45331</td>\n",
       "      <td>{2.332752227783203 1.1542993783950806 2.333015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35639</td>\n",
       "      <td>{8.562759399414062 2.1747426986694336 8.564172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33770</td>\n",
       "      <td>{2.200969934463501 0.9442633390426636 2.201041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42479</td>\n",
       "      <td>{73.32339477539062 51.60209655761719 234.37561...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44556</td>\n",
       "      <td>{162.06549072265625 0.0720682144165039 162.065...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                        predictions\n",
       "0     45331  {2.332752227783203 1.1542993783950806 2.333015...\n",
       "1     35639  {8.562759399414062 2.1747426986694336 8.564172...\n",
       "2     33770  {2.200969934463501 0.9442633390426636 2.201041...\n",
       "3     42479  {73.32339477539062 51.60209655761719 234.37561...\n",
       "4     44556  {162.06549072265625 0.0720682144165039 162.065..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submit.to_csv('my_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
