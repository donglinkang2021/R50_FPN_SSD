{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估模型\n",
    "\n",
    "上面的测试过程是一张一张图片进行预测的，这样的话速度会很慢，所以我们可以对图片进行批量处理，这样的话速度会快很多。所以我们需要对预测函数进行修改，使其能够批量处理图片。\n",
    "\n",
    "### 定义测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((256, 256))\n",
    "])\n",
    "\n",
    "# 将灰度图的数据集转换成RGB图像\n",
    "transform_gray = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((256, 256))\n",
    "])\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            data_dir, \n",
    "            img_paths,\n",
    "            transform=transform,\n",
    "            transform_gray=transform_gray\n",
    "        ):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.transform_gray = transform_gray\n",
    "        # self.imgs = os.listdir(data_dir)\n",
    "        self.imgs = img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.data_dir, self.imgs[idx])\n",
    "        img = Image.open(img_path)\n",
    "        if img.mode == 'RGB':\n",
    "            img = self.transform(img)\n",
    "        elif img.mode == 'L':\n",
    "            img = self.transform_gray(img)\n",
    "        return img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看提交格式\n",
    "\n",
    "查看提交格式先提前保存好测试集的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45331</td>\n",
       "      <td>{265.362 70.297 335.99100000000004 165.1499999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35639</td>\n",
       "      <td>{90.562 96.953 138.94299999999998 162.86599999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33770</td>\n",
       "      <td>{407.708 119.523 446.774 166.555 0.58494 6}{41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42479</td>\n",
       "      <td>{472.504 137.652 505.01300000000003 183.505 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44556</td>\n",
       "      <td>{447.187 46.098 521.98 83.03 0.65175 2}{453.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                        predictions\n",
       "0     45331  {265.362 70.297 335.99100000000004 165.1499999...\n",
       "1     35639  {90.562 96.953 138.94299999999998 162.86599999...\n",
       "2     33770  {407.708 119.523 446.774 166.555 0.58494 6}{41...\n",
       "3     42479  {472.504 137.652 505.01300000000003 183.505 0....\n",
       "4     44556  {447.187 46.098 521.98 83.03 0.65175 2}{453.01..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "submit_examples = pd.read_csv('starting_kit/test.csv', header = 0)\n",
    "submit_examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submit = pd.DataFrame(columns=['image_id', 'predictions'])\n",
    "my_submit['image_id'] = submit_examples['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>predictions</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45331</td>\n",
       "      <td>{265.362 70.297 335.99100000000004 165.1499999...</td>\n",
       "      <td>0045331.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35639</td>\n",
       "      <td>{90.562 96.953 138.94299999999998 162.86599999...</td>\n",
       "      <td>0035639.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33770</td>\n",
       "      <td>{407.708 119.523 446.774 166.555 0.58494 6}{41...</td>\n",
       "      <td>0033770.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42479</td>\n",
       "      <td>{472.504 137.652 505.01300000000003 183.505 0....</td>\n",
       "      <td>0042479.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44556</td>\n",
       "      <td>{447.187 46.098 521.98 83.03 0.65175 2}{453.01...</td>\n",
       "      <td>0044556.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                        predictions   image_path\n",
       "0     45331  {265.362 70.297 335.99100000000004 165.1499999...  0045331.jpg\n",
       "1     35639  {90.562 96.953 138.94299999999998 162.86599999...  0035639.jpg\n",
       "2     33770  {407.708 119.523 446.774 166.555 0.58494 6}{41...  0033770.jpg\n",
       "3     42479  {472.504 137.652 505.01300000000003 183.505 0....  0042479.jpg\n",
       "4     44556  {447.187 46.098 521.98 83.03 0.65175 2}{453.01...  0044556.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将submit_examples中的image_id转换成文件路径列表，具体形式为'%07d.jpg'%show_img_id\n",
    "submit_examples['image_path'] = submit_examples['image_id'].apply(lambda x: '%07d.jpg'%x)\n",
    "submit_examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0045331.jpg', '0035639.jpg', '0033770.jpg', '0042479.jpg', '0044556.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_paths = submit_examples['image_path'].tolist()\n",
    "img_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongl\\AppData\\Local\\Temp/ipykernel_19048/2862501199.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_images['width'][i] = img.size[0]\n",
      "C:\\Users\\dongl\\AppData\\Local\\Temp/ipykernel_19048/2862501199.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_images['height'][i] = img.size[1]\n"
     ]
    }
   ],
   "source": [
    "# 先建立一个csv文件储存测试集图片信息\n",
    "test_images = pd.DataFrame(columns=['image_id', 'image_path', 'width', 'height'])\n",
    "test_images['image_id'] = submit_examples['image_id']\n",
    "test_images['image_path'] = submit_examples['image_path']\n",
    "for i in range(len(submit_examples)):\n",
    "    img = Image.open('./dl_detection/test/%07d.jpg'%submit_examples['image_id'][i])\n",
    "    test_images['width'][i] = img.size[0]\n",
    "    test_images['height'][i] = img.size[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.to_csv('test_images.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0045331.jpg', 16362)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dir = \"./dl_detection/test/\"\n",
    "Cocodata_test = TestDataset(\n",
    "    test_data_dir,\n",
    "    img_paths\n",
    ")\n",
    "Cocodata_test.imgs[0], Cocodata_test.__len__()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始批量预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.device import try_gpu\n",
    "from mydet.model import R50_FPN_SSD\n",
    "import torch\n",
    "device = try_gpu()\n",
    "net = torch.load('checkpoint/resnet50_fpn_ssd.pth',map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    Cocodata_test,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mydet.bbox.postprocessor import BBoxPostProcessor\n",
    "from mydet.bbox.postprocessor import bbox_filter\n",
    "import torch.nn.functional as F\n",
    "from utils.submit import bboxListToStr\n",
    "\n",
    "bbpp = BBoxPostProcessor(\n",
    "    nms_threshold=0.5,\n",
    "    neg_threshold=0.00999\n",
    ")\n",
    "\n",
    "def predict_batch(X, batch_idx):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        batch_size = X.shape[0]\n",
    "        anchors, cls_preds, bbox_preds = net(X.to(device))\n",
    "        cls_probs = F.softmax(cls_preds, dim=2).permute(0, 2, 1) # 利用softmax转换成概率\n",
    "        output = bbpp.multibox_detection(cls_probs, bbox_preds, anchors)\n",
    "        # 去除掉背景类\n",
    "        for sample_idx in range(batch_size):\n",
    "            # 获取图片的宽和高信息\n",
    "            image_idx = batch_idx * batch_size + sample_idx\n",
    "            w = test_images['width'][image_idx]\n",
    "            h = test_images['height'][image_idx]\n",
    "            bbox_scale = torch.tensor([w, h, w, h], dtype=torch.float32, device=device)\n",
    "            # 去除掉背景类\n",
    "            idx = [i for i, sample in enumerate(output[sample_idx]) if sample[0] != -1]\n",
    "            sample_without_background = output[sample_idx][idx]\n",
    "            # 过滤掉一些预测框\n",
    "            sample_good = bbox_filter(sample_without_background)\n",
    "            # 如果一个类别的预测框超过300个，只取前300个（置信度从高到低排序）\n",
    "            if len(sample_good) > 300:\n",
    "                sample_good = sample_good[:300]\n",
    "\n",
    "            bbox_xyxy = sample_good[:, 2:] * bbox_scale\n",
    "            bbox_labels = sample_good[:, 0]\n",
    "            bbox_confs = sample_good[:, 1]\n",
    "\n",
    "            sample_good = torch.cat(\n",
    "                [\n",
    "                    bbox_xyxy,\n",
    "                    bbox_confs.unsqueeze(1),\n",
    "                    bbox_labels.unsqueeze(1),\n",
    "                ],\n",
    "                dim=1\n",
    "            )\n",
    "\n",
    "            # 将预测框转换成字符串并保存到my_submit中\n",
    "            my_submit.loc[image_idx, 'predictions'] = bboxListToStr(sample_good.cpu().numpy().tolist())\n",
    "            print('batch_idx: %d, sample_idx: %d, sample_good: %d' % (batch_idx, sample_idx, len(sample_good)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx: 0, sample_idx: 0, sample_good: 164\n",
      "batch_idx: 0, sample_idx: 1, sample_good: 234\n",
      "batch_idx: 0, sample_idx: 2, sample_good: 109\n",
      "batch_idx: 0, sample_idx: 3, sample_good: 125\n",
      "batch_idx: 1, sample_idx: 0, sample_good: 173\n",
      "batch_idx: 1, sample_idx: 1, sample_good: 267\n",
      "batch_idx: 1, sample_idx: 2, sample_good: 236\n",
      "batch_idx: 1, sample_idx: 3, sample_good: 223\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19048/2843220173.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 预测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpredict_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19048/3841304380.py\u001b[0m in \u001b[0;36mpredict_batch\u001b[1;34m(X, batch_idx)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0manchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcls_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 利用softmax转换成概率\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbbpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultibox_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m# 去除掉背景类\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Desktop2\\DL_Foundation\\assignment\\lastwork\\mydet\\bbox\\postprocessor.py\u001b[0m in \u001b[0;36mmultibox_detection\u001b[1;34m(self, cls_probs, offset_preds, anchors)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mpredicted_bb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbbox_coder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mkeep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbbox_nms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_bb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnms_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;31m# 找到所有的non_keep索引，并将类设置为背景\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Desktop2\\DL_Foundation\\assignment\\lastwork\\mydet\\bbox\\iou_nms.py\u001b[0m in \u001b[0;36mbbox_nms\u001b[1;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         iou = bbox_iou(\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "for batch_idx, X in enumerate(test_dataloader):\n",
    "    predict_batch(X, batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45331</td>\n",
       "      <td>{0.0 0.9972484707832336 0.0013790568336844444 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35639</td>\n",
       "      <td>{0.0 0.9999841451644897 0.013586888089776039 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33770</td>\n",
       "      <td>{0.0 0.9425780177116394 0.0011884903069585562 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42479</td>\n",
       "      <td>{0.0 0.5056626200675964 0.8542353510856628 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44556</td>\n",
       "      <td>{0.0 0.9996554851531982 0.0037318053655326366 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                        predictions\n",
       "0     45331  {0.0 0.9972484707832336 0.0013790568336844444 ...\n",
       "1     35639  {0.0 0.9999841451644897 0.013586888089776039 0...\n",
       "2     33770  {0.0 0.9425780177116394 0.0011884903069585562 ...\n",
       "3     42479  {0.0 0.5056626200675964 0.8542353510856628 0.0...\n",
       "4     44556  {0.0 0.9996554851531982 0.0037318053655326366 ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submit.to_csv('my_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
